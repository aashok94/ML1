{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array as a\n",
    "from random import random\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# input dataset\n",
    "filename1 = \"BIG_DWH_Training.csv\"\n",
    "df1 = pd.read_csv( filename1, header=None )\n",
    "df1.rename(columns={0: 'Index', 1: 'Height', 2: 'Weight', 3:'Gender'}, inplace=True)\n",
    "df1 = df1.drop(columns = \"Index\")\n",
    "\n",
    "data1=df1.replace({'Gender': -1}, 0)\n",
    "data1 = shuffle(data1)\n",
    "\n",
    "#normalize data\n",
    "normalize = preprocessing.StandardScaler().fit(data1.iloc[:, 1:3].values)\n",
    "new_df1 = normalize.transform(data1.iloc[:, 1:3].values)\n",
    "data1['Height'] = new_df1[:, 0]\n",
    "data1['Weight'] = new_df1[:, 1]\n",
    "\n",
    "#divide data into training and validation sets\n",
    "train, validation = train_test_split(data1, test_size=0.05)\n",
    "\n",
    "featuresTrain = train[['Height','Weight']].values.tolist()\n",
    "featuresTrain = a(featuresTrain)\n",
    "genderTrain = train[['Gender']].values.tolist()\n",
    "genderTrain = a(genderTrain)\n",
    "\n",
    "featuresVal = validation[['Height','Weight']].values.tolist()\n",
    "featuresVal = a(featuresVal)\n",
    "genderVal = validation[['Gender']].values.tolist()\n",
    "genderVal = a(genderVal)\n",
    "\n",
    "#test data set\n",
    "filename2 = \"DWH_Test.csv\"\n",
    "df2 = pd.read_csv( filename2, header=None )\n",
    "df2.rename(columns={0: 'Index', 1: 'Height', 2: 'Weight', 3:'Gender'}, inplace=True)\n",
    "df2 = df2.drop(columns = \"Index\")\n",
    "\n",
    "data2=df2.replace({'Gender': -1}, 0)\n",
    "\n",
    "#normalize data\n",
    "normalize = preprocessing.StandardScaler().fit(data2.iloc[:, 1:3].values)\n",
    "new_df2 = normalize.transform(data2.iloc[:, 1:3].values)\n",
    "data2['Height'] = new_df2[:, 0]\n",
    "data2['Weight'] = new_df2[:, 1]\n",
    "\n",
    "featuresTest = data2[['Height','Weight']].values.tolist()\n",
    "featuresTest = a(featuresTest)\n",
    "genderTest = data2[['Gender']].values.tolist()\n",
    "genderTest = a(genderTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ :  5\n",
      "Ψ : 0.9\n",
      "Last 5 validation error:  []\n",
      "Last 5 validation error:  [0.54583879 0.76475983 0.70158324 0.72972112 0.66352204]\n",
      "\n",
      "Training accuracies: [46. 66. 38. ... 56. 48. 50.]\n",
      "Validation accuracies: [70. 38. 46. 42. 52.]\n",
      "End of training for λ = 5 . Weights found to be as below:- \n",
      "\n",
      "Layer 1:\n",
      "  [[ 0.37516271  0.15747002]\n",
      " [-0.20290279 -0.3314144 ]\n",
      " [-0.17221443 -0.19179876]\n",
      " [-1.00707421 -0.22825695]\n",
      " [ 0.49845841 -0.19935595]]  \n",
      " Layer 2:\n",
      "  [[-0.64395945  0.23942659  0.26021896  0.50301353  1.34051966]\n",
      " [ 0.26996663 -0.24704966 -0.5202977  -0.03175176 -0.2309165 ]\n",
      " [-0.82112341  0.02435452 -0.30686432  1.49454632  0.05933619]\n",
      " [-0.25280571 -0.48894054  0.03443715  0.04199326 -1.15255846]\n",
      " [ 0.18938483  0.1905991   0.80152569 -0.4563081  -0.25455455]]  \n",
      " Layer 3: \n",
      " [[-2.17816289  2.12634903  0.60326951  1.79366829  0.89544965]]\n",
      "Accuracy :  55.55555555555556 %\n",
      "\n",
      "λ :  7\n",
      "Ψ : 0.9\n",
      "Last 5 validation error:  [0.54583879 0.76475983 0.70158324 0.72972112 0.66352204]\n",
      "\n",
      "Training accuracies: [46. 66. 38. ... 56. 36. 52.]\n",
      "Validation accuracies: [70. 38. 46. 42. 52.]\n",
      "End of training for λ = 7 . Weights found to be as below:- \n",
      "\n",
      "Layer 1:\n",
      "  [[ 0.38153401  0.16384131]\n",
      " [-0.19653149 -0.32504311]\n",
      " [-0.16584314 -0.18542747]\n",
      " [-1.00070292 -0.22188566]\n",
      " [ 0.50482971 -0.19298466]]  \n",
      " Layer 2:\n",
      "  [[-0.64630021  0.23708584  0.25787821  0.50067277  1.3381789 ]\n",
      " [ 0.26762587 -0.24939041 -0.52263846 -0.03409252 -0.23325725]\n",
      " [-0.82346416  0.02201377 -0.30920508  1.49220556  0.05699543]\n",
      " [-0.25514646 -0.49128129  0.03209639  0.0396525  -1.15489922]\n",
      " [ 0.18704407  0.18825835  0.79918494 -0.45864886 -0.25689531]]  \n",
      " Layer 3: \n",
      " [[-2.24155647  2.06295545  0.53987593  1.73027471  0.83205607]]\n",
      "Accuracy :  55.55555555555556 %\n",
      "\n",
      "λ :  11\n",
      "Ψ : 0.9\n",
      "Last 5 validation error:  [0.54583879 0.76475983 0.70158324 0.72972112 0.66352204]\n",
      "\n",
      "Training accuracies: [46. 66. 38. ... 46. 52. 54.]\n",
      "Validation accuracies: [70. 38. 46. 42. 52.]\n",
      "End of training for λ = 11 . Weights found to be as below:- \n",
      "\n",
      "Layer 1:\n",
      "  [[ 0.39049031  0.17279761]\n",
      " [-0.18757519 -0.3160868 ]\n",
      " [-0.15688683 -0.17647116]\n",
      " [-0.99174661 -0.21292935]\n",
      " [ 0.51378601 -0.18402835]]  \n",
      " Layer 2:\n",
      "  [[-0.64791278  0.23547326  0.25626563  0.49906019  1.33656633]\n",
      " [ 0.26601329 -0.25100299 -0.52425104 -0.03570509 -0.23486983]\n",
      " [-0.82507674  0.02040119 -0.31081766  1.49059299  0.05538285]\n",
      " [-0.25675904 -0.49289387  0.03048381  0.03803993 -1.1565118 ]\n",
      " [ 0.1854315   0.18664577  0.79757236 -0.46026144 -0.25850788]]  \n",
      " Layer 3: \n",
      " [[-2.31607091  1.98844102  0.4653615   1.65576028  0.75754163]]\n",
      "Accuracy :  55.55555555555556 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    #fn for initial weight creation of NN\n",
    "    def create_network(neuron_in, neuron_out):    \n",
    "        layer = np.random.randn(neuron_out,neuron_in) * np.sqrt(2/neuron_out)  \n",
    "        return layer\n",
    "    \n",
    "    def sigmoid(x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    # Forward propagate: takes weights and features and returns activation of each neuron in every layer of NN\n",
    "    def forward_propogation(features, ann1, ann2, ann3):\n",
    "        activation = [] #list\n",
    "        activation1 = []\n",
    "        activation2 = []\n",
    "        \n",
    "        for row in features:\n",
    "            act1 = np.dot(ann1, row)\n",
    "            act1 = NeuralNetwork.sigmoid(act1) \n",
    "            activation1.append(act1)\n",
    "            \n",
    "            act2 = np.dot(ann2, act1)\n",
    "            act2 = NeuralNetwork.sigmoid(act2)\n",
    "            activation2.append(act2)\n",
    "            \n",
    "            act3 = np.dot(ann3, act2)\n",
    "            act3 = NeuralNetwork.sigmoid(act3)\n",
    "            activation.append(act3)\n",
    "            \n",
    "        activation1 = a(activation1)\n",
    "        activation2 = a(activation2)\n",
    "        activation = a(activation)\n",
    "\n",
    "        return activation1, activation2, activation\n",
    "    \n",
    "    def sigmoid_derivative(x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    # Backpropagate : Computes gradient of each layer and error of every iteration\n",
    "    def backward_propagation(ann1, ann2, ann3, actual, a1, a2, a3):        \n",
    "        error = []\n",
    "        dError = []\n",
    "        sigDer3 = []\n",
    "        delta3 = []\n",
    "        gradient3=[]\n",
    "        delta2 = []\n",
    "        gradient2=[]\n",
    "        sigDer2=[]\n",
    "        delta1 = []\n",
    "        gradient1=[]\n",
    "        sigDer1=[]\n",
    "        \n",
    "        for i in range(len(actual)):\n",
    "            \n",
    "            error.append(-(np.multiply(actual[i],np.log(a3[i])) + np.multiply(1-actual[i],np.log(1-a3[i]))))\n",
    "            dError.append(-((actual[i]/a3[i]) - ((1-actual[i])/(1-a3[i]))))\n",
    "            sigDer3.append(NeuralNetwork.sigmoid_derivative(a3[i]))\n",
    "            sigDer2.append(NeuralNetwork.sigmoid_derivative(a2[i]))\n",
    "            sigDer1.append(NeuralNetwork.sigmoid_derivative(a1[i]))\n",
    "            delta3.append(dError[i] * sigDer3[i])\n",
    "            \n",
    "        error= np.mean(error)\n",
    "\n",
    "        sigDer2 = a(sigDer2)  \n",
    "        sigDer1 = a(sigDer1)\n",
    "        \n",
    "        delta3 = a(delta3)      \n",
    "        gradient3 = np.multiply(delta3,a3)\n",
    "        gradient3 = np.divide(np.mean(gradient3),50)\n",
    "        \n",
    "        delta2 = np.dot(delta3,ann3)\n",
    "        delta2 = np.multiply(delta2,sigDer2)\n",
    "        gradient2 = np.multiply(delta2,a2)\n",
    "        gradient2 = np.divide(np.mean(gradient2),50)\n",
    "   \n",
    "        delta1 = np.dot(delta2,ann2)\n",
    "        delta1 = np.multiply(delta1,sigDer1)\n",
    "        gradient1 = np.multiply(delta1,a1)\n",
    "        gradient1 = np.divide(np.mean(gradient1),50)\n",
    "        \n",
    "        return gradient1, gradient2, gradient3, error   \n",
    "    \n",
    "    #updates weights based on Ψ, weights, gradients, and learning rate\n",
    "    def update_weights(syi, ann1, ann2, ann3, lr, g1, g2, g3): \n",
    "        \n",
    "        dell1= syi* dell1 - g1\n",
    "        term1 = lr*dell1\n",
    "        \n",
    "        dell2= syi* dell2 - g2\n",
    "        term2 = lr*dell2\n",
    "        \n",
    "        dell3= syi* dell3 - g3\n",
    "        term3 = lr*dell3\n",
    "        \n",
    "        \n",
    "        weights1 = np.subtract(ann1, term1)\n",
    "        weights2 = np.subtract(ann2, term2)\n",
    "        weights3 = np.subtract(ann3, term3)\n",
    "        \n",
    "        return weights1, weights2, weights3\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ann1 = NeuralNetwork.create_network(2,5)\n",
    "    ann2 = NeuralNetwork.create_network(5,5) \n",
    "    ann3 = NeuralNetwork.create_network(5,1)\n",
    "    \n",
    "    batchSizeTrain = 0\n",
    "#     batchSizeVal = 0\n",
    "    valErrorList = np.empty(0)\n",
    "#     trainAccuracy = np.empty(0)\n",
    "    valAccuracy = np.empty(0)\n",
    "    out = True\n",
    "    x=[5,7,11]\n",
    "    \n",
    "    for value in x:\n",
    "        print(\"λ : \", value)\n",
    "#         syi= np.random.random(1)[0]\n",
    "        syi=0.9\n",
    "        print(\"Ψ :\", syi)\n",
    "    \n",
    "        for i in range(1,1550):\n",
    "            if i%250 != 0:      #training\n",
    "#                 print(\"Inside Training batch\", i)  \n",
    "                featuresTrainSplit = featuresTrain[batchSizeTrain:batchSizeTrain+50]\n",
    "                genderTrainSplit = genderTrain[batchSizeTrain:batchSizeTrain+50]\n",
    "                activation1, activation2, activation3 = NeuralNetwork.forward_propogation(featuresTrainSplit, ann1, ann2, ann3)\n",
    "                avg_gradient1, avg_gradient2, avg_gradient3, avg_error = NeuralNetwork.backward_propagation(ann1, ann2, ann3, genderTrainSplit, activation1, activation2, activation3)\n",
    "#                 print(\"Error :\", avg_error)\n",
    "\n",
    "                resultTrain = 0\n",
    "                predictTrain= np.zeros(50)\n",
    "\n",
    "                for index in range(len(activation3)): \n",
    "                    if (activation3[index] < 0.5) :      #female\n",
    "                        predictTrain[index] = 0\n",
    "                        if (genderTrainSplit[index] == predictTrain[index]): \n",
    "                            resultTrain += 1                      \n",
    "                    else:               #classify as male\n",
    "                        predictTrain[index] = 1    \n",
    "                        if (genderTrainSplit[index] == predictTrain[index]): \n",
    "                            resultTrain += 1\n",
    "                t_acc = (resultTrain/50) * 100\n",
    "#                 print(\"Accuracy : \", t_acc ,\"%\")\n",
    "#                 print(\"\")\n",
    "                trainAccuracy = np.append(trainAccuracy, t_acc)\n",
    "                \n",
    "                ann1, ann2, ann3 = NeuralNetwork.update_weights(syi, ann1, ann2, ann3, value/i, avg_gradient1, avg_gradient2, avg_gradient3)\n",
    "                batchSizeTrain += 50\n",
    "\n",
    "            else:   #validation\n",
    "#                 print(\"\")\n",
    "#                 print(\"Inside Validation batch\", i)\n",
    "                featuresValSplit = featuresVal[batchSizeVal:batchSizeVal+50]\n",
    "                genderValSplit = genderVal[batchSizeVal:batchSizeVal+50]\n",
    "                activation1, activation2, activation3 = NeuralNetwork.forward_propogation(featuresValSplit, ann1, ann2, ann3)\n",
    "                avg_gradient1, avg_gradient2, avg_gradient3, avg_error = NeuralNetwork.backward_propagation(ann1, ann2, ann3, genderValSplit, activation1, activation2, activation3)\n",
    "#                 print(\"Error: \", avg_error)\n",
    "\n",
    "                if len(valErrorList) % 5 == 0:\n",
    "                    print(\"Last 5 validation error: \", valErrorList[-5:])\n",
    "#                     print(\"Error: \", avg_error)\n",
    "                    out = np.greater(valErrorList[-5:], avg_error)\n",
    "                    if False in out:\n",
    "                        break\n",
    "\n",
    "                valErrorList = np.append(valErrorList, avg_error)\n",
    "\n",
    "                resultVal = 0\n",
    "                predictVal = np.zeros(50)\n",
    "\n",
    "                for index in range(len(activation3)):\n",
    "                    if (activation3[index] < 0.5) :      #female\n",
    "                        predictVal[index] = 0\n",
    "                        if (genderValSplit[index] == predictVal[index]): \n",
    "                            resultVal += 1                      \n",
    "                    else:               #classify as male\n",
    "                        predictVal[index] = 1    \n",
    "                        if (genderValSplit[index] == predictVal[index]): \n",
    "                            resultVal += 1\n",
    "                v_acc = (resultVal/50) * 100 \n",
    "#                 print(\"Accuracy : \", v_acc ,\"%\")\n",
    "#                 print(\"\")\n",
    "\n",
    "                valAccuracy = np.append(valAccuracy, v_acc)\n",
    "\n",
    "                ann1, ann2, ann3 = NeuralNetwork.update_weights(syi, ann1, ann2, ann3, value/i, avg_gradient1, avg_gradient2, avg_gradient3)\n",
    "                batchSizeVal += 50 \n",
    "\n",
    "        print(\"\\nTraining accuracies:\", trainAccuracy)\n",
    "        print(\"Validation accuracies:\", valAccuracy)\n",
    "        print(\"End of training for λ =\", value,\". Weights found to be as below:- \")\n",
    "        print(\"\\nLayer 1:\\n \", ann1, \" \\n Layer 2:\\n \",ann2,\"\", \"\\n Layer 3: \\n\", ann3)\n",
    "        \n",
    "        #testing set\n",
    "        activation1, activation2, activation3 = NeuralNetwork.forward_propogation(featuresTest, ann1, ann2, ann3)\n",
    "        resultTest = 0\n",
    "        predictTest= np.zeros(45)\n",
    "\n",
    "        for index in range(len(genderTest)): \n",
    "            if (activation3[index] < 0.5): #female\n",
    "                predictTest[index] = 0\n",
    "                if (genderTest[index] == predictTest[index]): \n",
    "                    resultTest += 1                      \n",
    "            else:               #classify as male\n",
    "                predictTest[index] = 1   \n",
    "                if (genderTest[index] == predictTest[index]): \n",
    "                    resultTest += 1\n",
    "        t_acc = (resultTest/45) * 100  \n",
    "       \n",
    "        print(\"Accuracy : \", t_acc ,\"%\")\n",
    "        print(\"\")\n",
    "    value += 1 #next value of λ\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
