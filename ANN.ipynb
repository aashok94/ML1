{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array as a\n",
    "from random import random\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "# input dataset\n",
    "filename1 = \"BIG_DWH_Training.csv\"\n",
    "df1 = pd.read_csv( filename1, header=None )\n",
    "df1.rename(columns={0: 'Index', 1: 'Height', 2: 'Weight', 3:'Gender'}, inplace=True)\n",
    "df1 = df1.drop(columns = \"Index\")\n",
    "\n",
    "data1=df1.replace({'Gender': -1}, 0)\n",
    "data1 = shuffle(data1)\n",
    "\n",
    "#normalize data\n",
    "normalize = preprocessing.StandardScaler().fit(data1.iloc[:, 1:3].values)\n",
    "new_df1 = normalize.transform(data1.iloc[:, 1:3].values)\n",
    "data1['Height'] = new_df1[:, 0]\n",
    "data1['Weight'] = new_df1[:, 1]\n",
    "\n",
    "#divide data into training and validation sets\n",
    "train, validation = train_test_split(data1, test_size=0.05)\n",
    "\n",
    "featuresTrain = train[['Height','Weight']].values.tolist()\n",
    "featuresTrain = a(featuresTrain)\n",
    "genderTrain = train[['Gender']].values.tolist()\n",
    "genderTrain = a(genderTrain)\n",
    "\n",
    "featuresVal = validation[['Height','Weight']].values.tolist()\n",
    "featuresVal = a(featuresVal)\n",
    "genderVal = validation[['Gender']].values.tolist()\n",
    "genderVal = a(genderVal)\n",
    "\n",
    "#test data set\n",
    "filename2 = \"DWH_Test.csv\"\n",
    "df2 = pd.read_csv( filename2, header=None )\n",
    "df2.rename(columns={0: 'Index', 1: 'Height', 2: 'Weight', 3:'Gender'}, inplace=True)\n",
    "df2 = df2.drop(columns = \"Index\")\n",
    "\n",
    "data2=df2.replace({'Gender': -1}, 0)\n",
    "\n",
    "#normalize data\n",
    "normalize = preprocessing.StandardScaler().fit(data2.iloc[:, 1:3].values)\n",
    "new_df2 = normalize.transform(data2.iloc[:, 1:3].values)\n",
    "data2['Height'] = new_df2[:, 0]\n",
    "data2['Weight'] = new_df2[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n",
      "(50, 1)\n",
      "(50, 1)\n",
      "(50, 1)\n",
      "\n",
      "Training accuracies: [50. 52. 54. 54.]\n",
      "Validation accuracies: []\n",
      "End of training. Weights found to be as below:- \n",
      "\n",
      "Layer 1:\n",
      "  [[ 0.39931276 -0.21889181]\n",
      " [-0.1068288  -0.30496878]\n",
      " [-0.45343286  0.23089769]\n",
      " [ 0.31493661 -0.3268117 ]\n",
      " [-0.59686982  0.38485152]]  \n",
      " Layer 2:\n",
      "  [[-0.36289102 -0.04581594  0.95828906  0.20357033 -0.47006621]\n",
      " [ 0.52168981  0.33109184 -0.01054542 -0.70416093 -0.08964089]\n",
      " [-0.2463336  -0.32992994 -0.25979413 -0.01808637 -0.59831496]\n",
      " [ 0.54237695 -0.8896685  -0.99805062 -0.95997024  0.07142816]\n",
      " [ 0.71284468  0.528435    0.67593766 -0.6393647   1.05608375]]  \n",
      " Layer 3: \n",
      " [[-1.88940393  1.8877302  -0.79013443  0.88625507 -0.39185512]]\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    #fn for initial weight creation of NN\n",
    "    def create_network(neuron_in, neuron_out):    \n",
    "        layer = np.random.randn(neuron_out,neuron_in) * np.sqrt(2/neuron_out)  \n",
    "        return layer\n",
    "    \n",
    "    def sigmoid(x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    # Forward propagate: takes weights and features and returns activation of each neuron in every layer of NN\n",
    "    def forward_propogation(features, ann1, ann2, ann3):\n",
    "        activation = [] #list\n",
    "        activation1 = []\n",
    "        activation2 = []\n",
    "        \n",
    "        for row in features:\n",
    "            act1 = np.dot(ann1, row)\n",
    "            act1 = NeuralNetwork.sigmoid(act1) \n",
    "            activation1.append(act1)\n",
    "            \n",
    "            act2 = np.dot(ann2, act1)\n",
    "            act2 = NeuralNetwork.sigmoid(act2)\n",
    "            activation2.append(act2)\n",
    "            \n",
    "            act3 = np.dot(ann3, act2)\n",
    "            act3 = NeuralNetwork.sigmoid(act3)\n",
    "            activation.append(act3)\n",
    "            \n",
    "        activation1 = a(activation1)\n",
    "        activation2 = a(activation2)\n",
    "        activation = a(activation)\n",
    "\n",
    "        return activation1, activation2, activation\n",
    "    \n",
    "    def sigmoid_derivative(x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    # Backpropagate : Computes gradient of each layer and error of every iteration\n",
    "    def backward_propagation(ann1, ann2, ann3, actual, a1, a2, a3):\n",
    "        \n",
    "        error = []\n",
    "        dError = []\n",
    "        sigDer3 = []\n",
    "        delta3 = []\n",
    "        gradient3=[]\n",
    "        delta2 = []\n",
    "        gradient2=[]\n",
    "        sigDer2=[]\n",
    "        delta1 = []\n",
    "        gradient1=[]\n",
    "        sigDer1=[]\n",
    "        \n",
    "        for i in range(len(actual)):\n",
    "            \n",
    "            error.append(-(np.multiply(actual[i],np.log(a3[i])) + np.multiply(1-actual[i],np.log(1-a3[i]))))\n",
    "            dError.append(-((actual[i]/a3[i]) - ((1-actual[i])/(1-a3[i]))))\n",
    "            sigDer3.append(NeuralNetwork.sigmoid_derivative(a3[i]))\n",
    "            sigDer2.append(NeuralNetwork.sigmoid_derivative(a2[i]))\n",
    "            sigDer1.append(NeuralNetwork.sigmoid_derivative(a1[i]))\n",
    "            delta3.append(dError[i] * sigDer3[i])\n",
    "           \n",
    "        error= np.mean(error)\n",
    "\n",
    "        sigDer2 = a(sigDer2)  \n",
    "        sigDer1 = a(sigDer1)\n",
    "        \n",
    "        delta3 = a(delta3)      \n",
    "        gradient3 = np.multiply(delta3,a3)\n",
    "        gradient3 = np.divide(np.mean(gradient3),50)\n",
    "        \n",
    "        delta2 = np.dot(delta3,ann3)\n",
    "        delta2 = np.multiply(delta2,sigDer2)\n",
    "        gradient2 = np.multiply(delta2,a2)\n",
    "        gradient2 = np.divide(np.mean(gradient2),50)\n",
    "   \n",
    "        delta1 = np.dot(delta2,ann2)\n",
    "        delta1 = np.multiply(delta1,sigDer1)\n",
    "        gradient1 = np.multiply(delta1,a1)\n",
    "        gradient1 = np.divide(np.mean(gradient1),50)\n",
    "        \n",
    "        return gradient1, gradient2, gradient3, error   \n",
    "    \n",
    "    \n",
    "    #updates weights based on weights, gradients, and learning rate\n",
    "    def update_weights(ann1, ann2, ann3, lr, g1, g2, g3): \n",
    "\n",
    "        term1 = lr*g1\n",
    "        term2 = lr*g2\n",
    "        term3 = lr*g3\n",
    "        weights1 = np.subtract(ann1, term1)\n",
    "        weights2 = np.subtract(ann2, term2)\n",
    "        weights3 = np.subtract(ann3, term3)\n",
    "        \n",
    "        return weights1, weights2, weights3\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ann1 = NeuralNetwork.create_network(2,5)\n",
    "    ann2 = NeuralNetwork.create_network(5,5) \n",
    "    ann3 = NeuralNetwork.create_network(5,1)\n",
    "    \n",
    "    batchSizeTrain = 0\n",
    "    batchSizeVal = 0\n",
    "    valErrorList = np.empty(0)\n",
    "    trainAccuracy = np.empty(0)\n",
    "    valAccuracy = np.empty(0)\n",
    "    out = True\n",
    "    \n",
    "    for i in range(1,1000):\n",
    "        if i%250 != 0:  \n",
    "            \n",
    "#             print(\"Inside Training batch\", i)\n",
    "            \n",
    "            featuresTrainSplit = featuresTrain[batchSizeTrain:batchSizeTrain+50]\n",
    "            genderTrainSplit = genderTrain[batchSizeTrain:batchSizeTrain+50]\n",
    "            activation1, activation2, activation3 = NeuralNetwork.forward_propogation(featuresTrainSplit, ann1, ann2, ann3)\n",
    "            avg_gradient1, avg_gradient2, avg_gradient3, avg_error = NeuralNetwork.backward_propagation(ann1, ann2, ann3, genderTrainSplit, activation1, activation2, activation3)\n",
    "#             print(\"Error :\", avg_error)\n",
    "            \n",
    "            resultTrain = 0\n",
    "            predictTrain= np.zeros(50)\n",
    "            \n",
    "            for index in range(len(activation3)): \n",
    "                if (activation3[index] < 0.5) :      #female\n",
    "                    predictTrain[index] = 0\n",
    "                    if (genderTrainSplit[index] == predictTrain[index]): \n",
    "                        resultTrain += 1                      \n",
    "                else:               #classify as male\n",
    "                    predictTrain[index] = 1    \n",
    "                    if (genderTrainSplit[index] == predictTrain[index]): \n",
    "                        resultTrain += 1\n",
    "            t_acc = (resultTrain/50) * 100\n",
    "#             print(\"Accuracy : \", t_acc ,\"%\")\n",
    "#             print(\"\")\n",
    "            trainAccuracy = np.append(trainAccuracy, t_acc)\n",
    "            \n",
    "            ann1, ann2, ann3 = NeuralNetwork.update_weights(ann1, ann2, ann3, 5/i, avg_gradient1, avg_gradient2, avg_gradient3)\n",
    "            batchSizeTrain += 50\n",
    "            \n",
    "        else:   \n",
    "#             print(\"\")\n",
    "#             print(\"Inside Validation batch\", i)\n",
    "            featuresValSplit = featuresVal[batchSizeVal:batchSizeVal+50]\n",
    "            genderValSplit = genderVal[batchSizeVal:batchSizeVal+50]\n",
    "            activation1, activation2, activation3 = NeuralNetwork.forward_propogation(featuresValSplit, ann1, ann2, ann3)\n",
    "            avg_gradient1, avg_gradient2, avg_gradient3, avg_error = NeuralNetwork.backward_propagation(ann1, ann2, ann3, genderValSplit, activation1, activation2, activation3)\n",
    "#             print(\"Error: \", avg_error)\n",
    "\n",
    "            \n",
    "            if len(valErrorList) % 5 == 0:\n",
    "                print(\"Last 5 error: \", valErrorList[-5:])\n",
    "                print(\"Average error: \", avg_error)\n",
    "                out = np.greater(valErrorList[-5:], avg_error)\n",
    "                if False in out:\n",
    "                    break\n",
    "                    \n",
    "            valErrorList = np.append(valErrorList, avg_error)\n",
    "                         \n",
    "            resultVal = 0\n",
    "            predictVal = np.zeros(50)\n",
    "            \n",
    "            for index in range(len(activation3)): \n",
    "                if (activation3[index] < 0.5) :      #female\n",
    "                    predictVal[index] = 0\n",
    "                    if (genderValSplit[index] == predictVal[index]): \n",
    "                        resultVal += 1                      \n",
    "                else:               #classify as male\n",
    "                    predictVal[index] = 1    \n",
    "                    if (genderValSplit[index] == predictVal[index]): \n",
    "                        resultVal += 1\n",
    "            v_acc = (resultVal/50) * 100 \n",
    "#             print(\"Accuracy : \", v_acc ,\"%\")\n",
    "#             print(\"\")\n",
    "            \n",
    "            valAccuracy = np.append(valAccuracy, v_acc)\n",
    "            \n",
    "            ann1, ann2, ann3 = NeuralNetwork.update_weights(ann1, ann2, ann3, 5/i, avg_gradient1, avg_gradient2, avg_gradient3)\n",
    "            batchSizeVal += 50\n",
    "            \n",
    "    print(\"\\nTraining accuracies:\", trainAccuracy)\n",
    "    print(\"Validation accuracies:\", valAccuracy)\n",
    "    print(\"End of training. Weights found to be as below:- \")\n",
    "    print(\"\\nLayer 1:\\n \", ann1, \" \\n Layer 2:\\n \",ann2,\"\", \"\\n Layer 3: \\n\", ann3)\n",
    "    \n",
    "#     #simple graph plot of accuracies\n",
    "#     # x axis values \n",
    "#     x = trainAccuracy \n",
    "#     # corresponding y axis values \n",
    "#     y = valAccuracy \n",
    "\n",
    "#     # plotting the points  \n",
    "#     plt.plot(x) \n",
    "\n",
    "#     # naming the x axis \n",
    "#     plt.xlabel('x - axis') \n",
    "#     # naming the y axis \n",
    "#     plt.ylabel('y - axis') \n",
    "\n",
    "#     # giving a title to my graph \n",
    "#     plt.title('Training and Validation accuraccies') \n",
    "\n",
    "#     # function to show the plot \n",
    "#     plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
